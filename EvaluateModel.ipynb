{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model\n",
    "\n",
    "This notebook compares the performance of the trained ActiNet model to a balanced random forest model, similar to the pypi:accelerometer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from actinet.models import ActivityClassifier, RFActivityClassifier\n",
    "from actinet.prepare import load_all_and_make_windows, extract_accelerometer_features, \\\n",
    "    prepare_accelerometer_data\n",
    "from actinet.evaluate import evaluate_models\n",
    "from actinet.utils.eval_utils import *\n",
    "\n",
    "WINSEC = 30 # seconds\n",
    "SAMPLE_RATE = 100 # Hz\n",
    "RESAMPLE_RATE = 30 # Hz\n",
    "N_JOBS = 8 # Set to higher number for quicker execution, but don't exceed max.\n",
    "\n",
    "DATAFILES = f\"data/capture24/P[0-9][0-9][0-9].csv.gz\"\n",
    "ANNOFILE = f\"data/capture24/annotation-label-dictionary.csv\"\n",
    "SAVEFOLDER = f\"data/capture24\"\n",
    "\n",
    "ACTIVITY_LABELS = [\"light\", \"moderate-vigorous\", \"sedentary\", \"sleep\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate actinet against accelerometer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the features each of the capture 24 files using the accelerometer package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(glob(\"data/capture24/bbaa/P[0-9][0-9][0-9]-epoch.csv.gz\")) != 151:\n",
    "    extract_accelerometer_features(n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the participant accelerometer data into the expected shape, containing the X, Y, T and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accelerometer feature data prepared\n",
    "if len(glob(f\"{SAVEFOLDER}/prepared/accelerometer/*.npy\")) == 4:\n",
    "    X_bbaa = np.load(f\"{SAVEFOLDER}/prepared/accelerometer/X.npy\")\n",
    "    Y_bbaa = np.load(f\"{SAVEFOLDER}/prepared/accelerometer/Y.npy\")\n",
    "    T_bbaa = np.load(f\"{SAVEFOLDER}/prepared/accelerometer/T.npy\")\n",
    "    P_bbaa = np.load(f\"{SAVEFOLDER}/prepared/accelerometer/pid.npy\")\n",
    "\n",
    "else:\n",
    "    X_bbaa, Y_bbaa, T_bbaa, P_bbaa = prepare_accelerometer_data(ANNOFILE, SAVEFOLDER, N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actinet data prepared\n",
    "if len(glob(f\"{SAVEFOLDER}/prepared/downsampling_linear_lowpass_None/*.npy\")) == 4:\n",
    "    X_actinet = np.load(f\"{SAVEFOLDER}/prepared/downsampling_linear_lowpass_None/X.npy\")\n",
    "    Y_actinet = np.load(f\"{SAVEFOLDER}/prepared/downsampling_linear_lowpass_None/Y.npy\")\n",
    "    T_actinet = np.load(f\"{SAVEFOLDER}/prepared/downsampling_linear_lowpass_None/T.npy\")\n",
    "    P_actinet = np.load(f\"{SAVEFOLDER}/prepared/downsampling_linear_lowpass_None/pid.npy\")\n",
    "\n",
    "else:\n",
    "    X_actinet, Y_actinet, T_actinet, P_actinet = load_all_and_make_windows(\n",
    "        datafiles=glob(DATAFILES), \n",
    "        annofile=ANNOFILE, \n",
    "        out_dir=SAVEFOLDER, \n",
    "        anno_label=\"Walmsley2020\",\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        winsec=WINSEC,\n",
    "        n_jobs=N_JOBS,\n",
    "        downsampling_method=\"linear\",\n",
    "        lowpass_hz=None,\n",
    "        resample_rate=RESAMPLE_RATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model using 5 fold stratified group cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actinet_res_path = \"outputs/actinet_vs_bbaa/actinet_results.pkl\"\n",
    "bbaa_res_path = \"outputs/actinet_vs_bbaa/rf_results.pkl\"\n",
    "\n",
    "if not os.path.exists(actinet_res_path) or not os.path.exists(bbaa_res_path):\n",
    "    bbaa_classifier = RFActivityClassifier(\n",
    "        winsec=WINSEC,\n",
    "        labels=ACTIVITY_LABELS,\n",
    "        n_estimators=1000,\n",
    "        oob_score=True,\n",
    "        sampling_strategy=\"not minority\",\n",
    "        replacement=True,\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    actinet_classifier = ActivityClassifier(\n",
    "        labels = np.unique(Y_actinet),\n",
    "        batch_size=1000,\n",
    "        device=\"cuda:0\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    res = evaluate_models(\n",
    "        actinet_classifier,\n",
    "        bbaa_classifier,\n",
    "        X_actinet,\n",
    "        X_bbaa,\n",
    "        Y_actinet,\n",
    "        Y_bbaa,\n",
    "        P_actinet,\n",
    "        P_bbaa,\n",
    "        T_actinet,\n",
    "        T_bbaa,\n",
    "        weights_path=\"models/evaluation_models/actinet_vs_bbaa_{}.pt\",\n",
    "        out_dir=\"outputs/actinet_vs_bbaa\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "results_bbaa = pd.read_pickle(bbaa_res_path)\n",
    "results_actinet = pd.read_pickle(actinet_res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_pid_df = pd.DataFrame([{'Fold': fold+1, \"Test Participant IDs\": \", \".join(sorted(set(group)))} for fold, group in results_actinet[\"group\"].items()]).set_index(\"Fold\")\n",
    "fold_pid_df.to_csv(\"outputs/actinet_vs_bbaa/fold_pids.csv\")\n",
    "fold_pid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'accelerometer': {'y': np.hstack(results_bbaa[\"Y_true\"]), \n",
    "                      'y_pred': np.hstack(results_bbaa[\"Y_pred\"]), \n",
    "                      'pid': np.hstack(results_bbaa[\"group\"])\n",
    "                      },\n",
    "    'actinet': {'y': np.hstack(results_actinet[\"Y_true\"]), \n",
    "                'y_pred': np.hstack(results_actinet[\"Y_pred\"]), \n",
    "                'pid': np.hstack(results_actinet[\"group\"])\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model, model_data in data.items():\n",
    "    for pid in np.unique(model_data['pid']):\n",
    "        mask = model_data['pid'] == pid\n",
    "        y_true = model_data['y'][mask]\n",
    "        y_pred = model_data['y_pred'][mask]\n",
    "        accuracy, f1, kappa, bacc = calculate_metrics(y_true, y_pred)\n",
    "        results.append({'Participant': pid, 'Model': model, \"Balanced Accuracy\": bacc,\n",
    "                        'Accuracy': accuracy, 'Macro F1': f1, 'Cohen Kappa': kappa,\n",
    "                        'Predicted': y_pred, 'True': y_true, \"Pred_dict\": DivDict(pd.value_counts(y_pred).to_dict())/120,\n",
    "                        \"True_dict\": DivDict(pd.value_counts(y_true).to_dict())/120, \n",
    "                        \"Len\": len(y_true)})\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model and calculate mean and standard deviation\n",
    "summary = results.groupby('Model')[['Accuracy',\n",
    "                                    'Balanced Accuracy',\n",
    "                                    'Cohen Kappa',\n",
    "                                    'Macro F1']].agg(lambda x: f\"{np.mean(x):.3f} \" + \n",
    "                                                                  f\"Â± {np.std(x):.3f}\")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"data/capture24/metadata.csv\")\n",
    "results_df = results.merge(metadata, left_on=\"Participant\", right_on=\"pid\")\n",
    "\n",
    "sex_mapping = {'F': 'Female', 'M': 'Male'}\n",
    "results_df['Sex'] = pd.Categorical(results_df['sex'].map(sex_mapping), ordered=True,\n",
    "                                   categories=sex_mapping.values())\n",
    "\n",
    "results_df['Age Band'] = pd.Categorical(results_df['age'], ordered=True,\n",
    "                                        categories=['18-29', '30-37', '38-52', '53+'])\n",
    "\n",
    "results_df.drop(columns=[\"age\", \"sex\", \"pid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "metrics = ['Accuracy', 'Balanced Accuracy', 'Cohen Kappa', 'Macro F1']\n",
    "p_values = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    acc_values = results_df.loc[results_df['Model'] == 'accelerometer', metric].values\n",
    "    actinet_values = results_df.loc[results_df['Model'] == 'actinet', metric].values\n",
    "    _, p_value = ttest_rel(acc_values, actinet_values)\n",
    "    p_values[metric] = p_value\n",
    "\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_difference_boxplots(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(results, 'Accuracy', modulus=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(results, 'Macro F1', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(results, 'Cohen Kappa', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(df, x, y='Macro F1', hue='Model'):\n",
    "    \"\"\"Plots boxplots of model performance by a specified variable\"\"\"\n",
    "    _, ax = plt.subplots(figsize=(5, 3), dpi=1000)\n",
    "    with sns.color_palette(\"Set1\"):\n",
    "        sns.boxplot(data=df, x=x, y=y, hue=hue, ax=ax)\n",
    "    ax.set_xlabel(\"Age Band\")\n",
    "    ax.set_ylabel(f\"Cohen's kappa score\")\n",
    "    plt.title(f\"Performance by {x}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplots(results_df, 'Age Band', y=\"Cohen Kappa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplots(results_df, 'Sex',  y=\"Cohen Kappa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model and calculate mean and standard deviation\n",
    "results_df.groupby(['Age Band', 'Model'])[['Cohen Kappa']].agg(lambda x: f\"{np.mean(x):.3f} \" + \n",
    "                                                                  f\"Â± {np.std(x):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model and calculate mean and standard deviation\n",
    "results_df.groupby(['Sex', 'Model'])[['Cohen Kappa']].agg(lambda x: f\"{np.mean(x):.3f} \" + \n",
    "                                                                  f\"Â± {np.std(x):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrices(results_df, group_by=None, save_path=None, fontsize=20):\n",
    "    \"\"\"Generates and plots confusion matrices for different subgroups.\"\"\" \n",
    "    if group_by is None:  # Full population\n",
    "        fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12, 6), dpi=800)\n",
    "        fig.suptitle(\"Confusion matrices for full Capture-24 population\\nusing 5-fold group cross-validation\", \n",
    "                     fontsize=fontsize)\n",
    "        \n",
    "        y_true_bbaa, y_pred_bbaa, y_true_actinet, y_pred_actinet, _ = build_confusion_matrix_data(results_df)\n",
    "        \n",
    "        plot_confusion_matrix(y_true_bbaa, y_pred_bbaa, 'accelerometer', ax=axs[0], fontsize=fontsize*0.8)\n",
    "        plot_confusion_matrix(y_true_actinet, y_pred_actinet, 'actinet', ax=axs[1], fontsize=fontsize*0.8)\n",
    "        fig.tight_layout()\n",
    "        plot_and_save_fig(fig, save_path)\n",
    "    \n",
    "    else:\n",
    "        unique_groups = results_df[group_by].cat.categories\n",
    "        fig = plt.figure(figsize=(12, 6*len(unique_groups)), dpi=800, constrained_layout=True)\n",
    "        fig.suptitle(f\"Confusion matrices for different {group_by.lower()} in \" +\n",
    "                     \"Capture-24 population\\nusing 5-fold group cross-validation\", fontsize=fontsize)\n",
    "\n",
    "        subfigs = fig.subfigures(nrows=len(unique_groups), ncols=1)\n",
    "        \n",
    "        for group, subfig in zip(unique_groups, subfigs):\n",
    "            y_true_bbaa, y_pred_bbaa, y_true_actinet, y_pred_actinet, population =\\\n",
    "                build_confusion_matrix_data(results_df, **{group_by.replace(' ', '_').lower(): group})\n",
    "\n",
    "            subfig.suptitle(f\"{group_by}: {group} (n = {population})\", fontsize=fontsize*0.9)\n",
    "            axs = subfig.subplots(nrows=1, ncols=2, sharey=True)\n",
    "\n",
    "            plot_confusion_matrix(y_true_bbaa, y_pred_bbaa, 'accelerometer', ax=axs[0], fontsize=fontsize*0.8)\n",
    "            plot_confusion_matrix(y_true_actinet, y_pred_actinet, 'actinet', ax=axs[1], fontsize=fontsize*0.8)\n",
    "        \n",
    "        plot_and_save_fig(fig, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confusion_matrices(results_df, save_path=\"outputs/actinet_vs_bbaa/full_population.pdf\", fontsize=18)\n",
    "generate_confusion_matrices(results_df, group_by=\"Sex\", save_path=\"outputs/actinet_vs_bbaa/by_sex.pdf\", fontsize=18)\n",
    "generate_confusion_matrices(results_df, group_by=\"Age Band\", save_path=\"outputs/actinet_vs_bbaa/by_age.pdf\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bland-Altman plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bland_altman_plots(results_df, save_path=\"outputs/actinet_vs_bbaa/bland_altman/full_population.pdf\")\n",
    "generate_bland_altman_plots(results_df[results_df[\"Sex\"]==\"Female\"], subset=\"female\",\n",
    "                            save_path=\"outputs/actinet_vs_bbaa/bland_altman/by_sex_female.pdf\")\n",
    "generate_bland_altman_plots(results_df[results_df[\"Sex\"]==\"Male\"], subset=\"male\",\n",
    "                            save_path=\"outputs/actinet_vs_bbaa/bland_altman/by_sex_male.pdf\")\n",
    "generate_bland_altman_plots(results_df, group_by=\"Age Band\", save_path=\"outputs/actinet_vs_bbaa/bland_altman/by_age.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actinet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
