{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to evaluate the model performance compare to different preprocessing approaches, as well as model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "from actinet.models import ActivityClassifier\n",
    "from actinet.prepare import load_all_and_make_windows\n",
    "from actinet.evaluate import evaluate\n",
    "\n",
    "WINSEC = 30 # seconds\n",
    "SAMPLE_RATE = 100 # Hz\n",
    "RESAMPLE_RATE = 30 # Hz\n",
    "N_JOBS = 8 # Set to higher number for quicker execution, but don't exceed max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1 - Actipy downsampling, no lp filter\n",
    "\n",
    "DATAFILES = f\"data/capture24/P[0-9][0-9][0-9].csv.gz\"\n",
    "ANNOFILE = f\"data/capture24/annotation-label-dictionary.csv\"\n",
    "SAVEFOLDER = f\"data/capture24\"\n",
    "\n",
    "if len(glob(f\"{SAVEFOLDER}/downsampling_nn_lowpass_None/*.npy\")) == 4:\n",
    "    X_nn = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_None/X.npy\")\n",
    "    Y_nn = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_None/Y.npy\")\n",
    "    T_nn = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_None/T.npy\")\n",
    "    pid_nn = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_None/pid.npy\")\n",
    "\n",
    "else:\n",
    "    X_nn, Y_nn, T_nn, pid_nn = load_all_and_make_windows(\n",
    "        datafiles=glob(DATAFILES), \n",
    "        annofile=ANNOFILE, \n",
    "        out_dir=SAVEFOLDER, \n",
    "        anno_label=\"Walmsley2020\",\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        winsec=WINSEC,\n",
    "        n_jobs=N_JOBS,\n",
    "        downsampling_method=\"nn\",\n",
    "        lowpass_hz=None,\n",
    "        resample_rate=RESAMPLE_RATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2 - Actipy downsampling, 15Hz lp filter\n",
    "\n",
    "DATAFILES = f\"data/capture24/P[0-9][0-9][0-9].csv.gz\"\n",
    "ANNOFILE = f\"data/capture24/annotation-label-dictionary.csv\"\n",
    "SAVEFOLDER = f\"data/capture24\"\n",
    "\n",
    "if len(glob(f\"{SAVEFOLDER}/downsampling_nn_lowpass_15/*.npy\")) == 4:\n",
    "    X_nn15 = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_15/X.npy\")\n",
    "    Y_nn15 = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_15/Y.npy\")\n",
    "    T_nn15 = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_15/T.npy\")\n",
    "    pid_nn15 = np.load(f\"{SAVEFOLDER}/downsampling_nn_lowpass_15/pid.npy\")\n",
    "\n",
    "else:\n",
    "    X_nn15, Y_nn15, T_nn15, pid_nn15 = load_all_and_make_windows(\n",
    "        datafiles=glob(DATAFILES), \n",
    "        annofile=ANNOFILE, \n",
    "        out_dir=SAVEFOLDER, \n",
    "        anno_label=\"Walmsley2020\",\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        winsec=WINSEC,\n",
    "        n_jobs=N_JOBS,\n",
    "        downsampling_method=\"nn\",\n",
    "        lowpass_hz=15,\n",
    "        resample_rate=RESAMPLE_RATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 3 - Linear downsampling, no lp filter\n",
    "\n",
    "DATAFILES = f\"data/capture24/P[0-9][0-9][0-9].csv.gz\"\n",
    "ANNOFILE = f\"data/capture24/annotation-label-dictionary.csv\"\n",
    "SAVEFOLDER = f\"data/capture24\"\n",
    "\n",
    "if len(glob(f\"{SAVEFOLDER}/downsampling_linear_lowpass_None/*.npy\")) == 4:\n",
    "    X_linear = np.load(f\"{SAVEFOLDER}/downsampling_linear_lowpass_None/X.npy\")\n",
    "    Y_linear = np.load(f\"{SAVEFOLDER}/downsampling_linear_lowpass_None/Y.npy\")\n",
    "    T_linear = np.load(f\"{SAVEFOLDER}/downsampling_linear_lowpass_None/T.npy\")\n",
    "    pid_linear = np.load(f\"{SAVEFOLDER}/downsampling_linear_lowpass_None/pid.npy\")\n",
    "\n",
    "else:\n",
    "    X_linear, Y_linear, T_linear, pid_linear = load_all_and_make_windows(\n",
    "        datafiles=glob(DATAFILES), \n",
    "        annofile=ANNOFILE, \n",
    "        out_dir=SAVEFOLDER, \n",
    "        anno_label=\"Walmsley2020\",\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        winsec=WINSEC,\n",
    "        n_jobs=N_JOBS,\n",
    "        downsampling_method=\"linear\",\n",
    "        lowpass_hz=None,\n",
    "        resample_rate=RESAMPLE_RATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/evaluation_models\"\n",
    "\n",
    "def reset_folder(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "reset_folder(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nn = ActivityClassifier(\n",
    "    labels = np.unique(Y_nn),\n",
    "    batch_size=1000,\n",
    "    device=\"cuda:0\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "Y_pred_nn = evaluate(classifier_nn, X_nn, Y_nn, pid_nn, T_nn, \n",
    "                     f\"{models_path}/downsampling_nn_lowpass_None_{{}}.pt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nn15 = ActivityClassifier(\n",
    "    labels = np.unique(Y_nn),\n",
    "    batch_size=1000,\n",
    "    device=\"cuda:0\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "Y_pred_nn15 = evaluate(classifier_nn15, X_nn15, Y_nn15, pid_nn15, T_nn15, \n",
    "                       f\"{models_path}/downsampling_nn_lowpass_15_{{}}.pt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_linear = ActivityClassifier(\n",
    "    labels = np.unique(Y_nn),\n",
    "    batch_size=1000,\n",
    "    device=\"cuda:0\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "Y_pred_linear = evaluate(classifier_linear, X_linear, Y_linear, pid_linear, T_linear,\n",
    "                         f\"{models_path}/downsampling_linear_lowpass_None_{{}}.pt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
    "\n",
    "data = {\n",
    "    'nearest neighbour no filter': {'y': Y_nn, 'y_pred': Y_pred_nn, 'pid': pid_nn},\n",
    "    'nearest neighbour 15Hz lp filter': {'y': Y_nn15, 'y_pred': Y_pred_nn15, 'pid': pid_nn15},\n",
    "    'linear downsampling no filter': {'y': Y_linear, 'y_pred': Y_pred_linear, 'pid': pid_linear}\n",
    "}\n",
    "\n",
    "# Define a function to calculate evaluation metrics for each participant\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return accuracy, f1, kappa\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Calculate metrics for each model and participant\n",
    "for model, model_data in data.items():\n",
    "    for pid in np.unique(model_data['pid']):\n",
    "        mask = model_data['pid'] == pid\n",
    "        y_true = model_data['y'][mask]\n",
    "        y_pred = model_data['y_pred'][mask]\n",
    "        accuracy, f1, kappa = calculate_metrics(y_true, y_pred)\n",
    "        results.append({'Participant': pid, 'Model': model, \n",
    "                        'Accuracy': accuracy, 'Macro F1': f1, 'Cohen Kappa': kappa})\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "# Aggregate results by participant\n",
    "agg_results = results.groupby('Model').agg({'Accuracy': ['mean', 'std'],\n",
    "                                                  'Macro F1': ['mean', 'std'],\n",
    "                                                  'Cohen Kappa': ['mean', 'std']})\n",
    "\n",
    "# Rename columns for clarity\n",
    "agg_results.columns = ['Accuracy Mean', 'Accuracy Std', 'Macro F1 Mean', 'Macro F1 Std', 'Cohen Kappa Mean', 'Cohen Kappa Std']\n",
    "\n",
    "\n",
    "def format_mean_std(mean, std):\n",
    "    return f\"{mean:.3f} \\u00B1 {std:.3f}\"\n",
    "\n",
    "agg_results[\"Accuracy\"] = agg_results.apply(lambda x: format_mean_std(x[\"Accuracy Mean\"], \n",
    "                                                                      x[\"Accuracy Std\"]), axis=1)\n",
    "\n",
    "agg_results[\"Macro F1\"] = agg_results.apply(lambda x: format_mean_std(x[\"Macro F1 Mean\"], \n",
    "                                                                      x[\"Macro F1 Std\"]), axis=1)\n",
    "\n",
    "agg_results[\"Cohen Kappa\"] = agg_results.apply(lambda x: format_mean_std(x[\"Cohen Kappa Mean\"], \n",
    "                                                                      x[\"Cohen Kappa Std\"]), axis=1)\n",
    "\n",
    "agg_results[[\"Accuracy\", \"Macro F1\", \"Cohen Kappa\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Plot confusion matrix for each model\n",
    "for model, model_data in data.items():\n",
    "    y_true = model_data['y']\n",
    "    y_pred = model_data['y_pred']\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')  # Normalized confusion matrix\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(cm, annot=True, fmt='.3f', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    plt.xticks(ticks=np.arange(len(cm))+0.5, labels=np.unique(y_true))\n",
    "    plt.yticks(ticks=np.arange(len(cm))+0.5, labels=np.unique(y_true))\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actinet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
